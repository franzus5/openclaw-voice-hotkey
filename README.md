# OpenClaw Voice Hotkey

Voice assistant for OpenClaw - press a hotkey, speak, get AI response.

## Features

- ðŸŽ¤ **Global hotkey** (`Cmd+Shift+Space`) to start voice recording
- ðŸ—£ï¸ **Local Whisper transcription** (no API calls, free)
- ðŸ¤– **OpenClaw integration** - sends transcription to your local OpenClaw instance
- ðŸ”Š **Audio response** - speaks the answer back using TTS
- ðŸ‡ºðŸ‡¦ **Ukrainian language support** - native Ukrainian TTS voice (Lada)

## How it works

1. Press and **hold** `Cmd+Shift+Space` â†’ recording starts
2. Speak your question while holding
3. Release hotkey â†’ recording stops, Whisper transcribes locally
4. Text sent to OpenClaw via CLI (`openclaw inject`)
5. OpenClaw response appears in your main chat (Telegram/etc)
6. *(Future: speak response aloud via TTS)*

## Requirements

- macOS 12.0+
- Python 3.9+
- OpenClaw running locally
- Homebrew (for dependencies)
- **Accessibility permissions** (for hotkey detection) - see [PERMISSIONS.md](PERMISSIONS.md)

## Installation

### Option 1: Local Setup (Recommended - like node_modules)

Everything installs **locally in the project** - no global pollution:

```bash
# Clone the repo
git clone https://github.com/franzus5/openclaw-voice-hotkey.git
cd openclaw-voice-hotkey

# Run local setup
chmod +x setup_local.sh
./setup_local.sh

# Run the assistant
./run.sh
```

This creates:
```
openclaw-voice-hotkey/
  â”œâ”€â”€ venv/              â† Python packages (local virtualenv)
  â”œâ”€â”€ models/
  â”‚   â”œâ”€â”€ whisper/       â† Whisper models (~74MB)
  â”‚   â””â”€â”€ tts/           â† TTS voice models
  â””â”€â”€ bin/               â† Piper binary
```

**No global installation!** Everything is self-contained.

### Option 2: Global Setup (Traditional)

```bash
# Clone the repo
git clone https://github.com/franzus5/openclaw-voice-hotkey.git
cd openclaw-voice-hotkey

# Run global setup
chmod +x setup.sh
./setup.sh

# Run the assistant
python3 voice_hotkey.py
```

This installs:
- Python packages globally
- Whisper models in `~/.cache/whisper/`
- Piper TTS locally in project

### Manual Installation

If you prefer manual setup:

```bash
# Install system dependencies
brew install portaudio ffmpeg

# Create venv
python3 -m venv venv
source venv/bin/activate

# Install packages
pip install -r requirements.txt

# Run
python3 voice_hotkey.py
```

## Configuration

Edit `config.json`:

```json
{
  "hotkey": "cmd+shift+space",
  "whisperModel": "base",
  "ttsEngine": "piper",
  "language": "uk",
  "inputDevice": null,
  "openclawBinary": "/Users/YOUR_USERNAME/.nvm/versions/node/v24.13.0/bin/openclaw",
  "piperBinary": "./bin/piper",
  "piperModelUK": "./models/tts/uk_UA-lada-x_low.onnx",
  "piperModelEN": "./models/tts/en_US-lessac-medium.onnx",
  "piperModel": "./models/tts/uk_UA-lada-x_low.onnx"
}
```

**Options:**

- `hotkey`: Keyboard shortcut (default: `cmd+shift+space`)
- `whisperModel`: Whisper model size (`tiny`, `base`, `small`, `medium`, `large`)
  - `tiny`: fastest, lowest quality (~39MB)
  - `base`: good balance (~74MB) - **recommended**
  - `small`: better quality (~244MB)
  - `medium`: high quality (~769MB)
  - `large`: best quality (~1.5GB)
- `ttsEngine`: Text-to-speech engine
  - `say`: macOS built-in (fast, decent quality)
  - `piper`: Local TTS (better quality, more natural, **supports Ukrainian**)
  - `sag`: ElevenLabs via skill (requires API key, cloud-based)
- `language`: Language for Piper TTS (`uk` or `en`)
  - `uk`: Ukrainian voice (Lada) - **default**
  - `en`: English voice (Lessac)
- `inputDevice`: Audio input device index (see device list on startup)
  - `null`: use system default
  - `2`: use device #2 (e.g., headset microphone)
  - Check device list when starting the assistant
- `openclawBinary`: Full path to OpenClaw CLI (auto-detected if not set)
  - Example: `~/.nvm/versions/node/v24.13.0/bin/openclaw`
  - If OpenClaw is not in PATH, set this explicitly
- `piperModelUK`: Path to Ukrainian voice model
- `piperModelEN`: Path to English voice model

## Usage

1. Start the assistant: `python3 voice_hotkey.py`
2. Press and hold `Cmd+Shift+Space`
3. Speak your question
4. Release the hotkey
5. Wait for transcription + AI response

## Architecture

### Data Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Hotkey    â”‚  Cmd+Shift+Space
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Record    â”‚  pyaudio â†’ audio.wav
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Whisper   â”‚  whisper audio.wav â†’ text
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  OpenClaw   â”‚  ws://127.0.0.1:18789
â”‚   Gateway   â”‚  send(text) â†’ response
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     TTS     â”‚  piper/say â†’ speech
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Project Structure

```
openclaw-voice-hotkey/
â”œâ”€â”€ voice_hotkey.py       # Main application
â”œâ”€â”€ config.json           # Configuration
â”œâ”€â”€ requirements.txt      # Python dependencies
â”œâ”€â”€ setup_local.sh        # Local setup (recommended)
â”œâ”€â”€ setup.sh              # Global setup
â”œâ”€â”€ run.sh                # Run with local env
â”œâ”€â”€ test_components.py    # Component tests
â”‚
â”œâ”€â”€ venv/                 # Python virtualenv (local)
â”‚   â””â”€â”€ lib/              # Python packages
â”‚
â”œâ”€â”€ models/               # AI models (local)
â”‚   â”œâ”€â”€ whisper/          # Speech recognition
â”‚   â”‚   â””â”€â”€ base.pt       # ~74MB
â”‚   â””â”€â”€ tts/              # Text-to-speech
â”‚       â”œâ”€â”€ uk_UA-lada-x_low.onnx      # Ukrainian
â”‚       â””â”€â”€ en_US-lessac-medium.onnx   # English
â”‚
â””â”€â”€ bin/                  # Binaries (local)
    â””â”€â”€ piper             # TTS engine
```

## Troubleshooting

### "This process is not trusted!" error

You need to grant **Accessibility** permissions to Terminal.

ðŸ‘‰ **See [PERMISSIONS.md](PERMISSIONS.md) for detailed instructions**

Quick fix:
1. System Settings â†’ Privacy & Security â†’ Accessibility
2. Add Terminal.app
3. Restart the assistant

### Hotkey not working

1. Check Accessibility permissions (see above)
2. Make sure you press **Cmd+Shift+Space** (all three keys)
3. Try restarting Terminal completely

### "No speech detected"

1. Check microphone permissions (System Settings â†’ Privacy & Security â†’ Microphone)
2. Speak clearly and hold hotkey while speaking
3. Recording duration must be > 0.5 seconds
4. Try testing microphone: `rec test.wav trim 0 3 && play test.wav`

### Message not appearing in OpenClaw

1. Make sure OpenClaw is running: `openclaw status`
2. Check you're in the main session (Telegram/etc)
3. Message is sent via `openclaw inject` command

## Roadmap

- [x] Create repo structure
- [x] Implement hotkey listener (pynput)
- [x] Implement audio recording (pyaudio)
- [x] Whisper CLI integration
- [x] Local TTS (Piper) with Ukrainian support
- [x] Self-contained setup (like node_modules)
- [ ] OpenClaw WebSocket client (in progress)
- [ ] Proper Cmd+Shift+Space detection (done, needs testing)
- [ ] Menu bar app (optional)
- [ ] Standalone .app bundle (no Terminal required)

## License

MIT
